{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and extraction of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### global functions\n",
    "We tried them at the first place on our model but unfortunaltelly (without any surprise) the extracted data isn't correlated with the zone of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_time(data_sample):\n",
    "    #returns total time of one user request conversation\n",
    "    return float(data_sample[-1][1])\n",
    "\n",
    "def total_len(data_sample):\n",
    "    #return total number of packages exchanged\n",
    "    return len(data_sample)\n",
    "\n",
    "def percentage_tcp(data_sample):\n",
    "    #returns percentage of tcp protocol was used\n",
    "    return sum([1 if(q[4]=='TCP') else 0 for q in data_sample])/len(data_sample)\n",
    "\n",
    "def percentage_tls(data_sample):\n",
    "    #returns percentage of tcp protocol was used\n",
    "    return sum([1 if(q[4]=='TLSv1.2') else 0 for q in data_sample])/len(data_sample)\n",
    "\n",
    "def avg_response_time(data_sample):\n",
    "    t = [float(q[1]) for q in data_sample]\n",
    "    return sum([j-i for i, j in zip(t[:-1], t[1:])])/(len(t)-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying basic functions, we did some test on the data to see what noise we could remove etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_source = set()\n",
    "set_dest = set()\n",
    "set_pairs = set()\n",
    "\n",
    "#In this cell we looked at the ip address\n",
    "\n",
    "for zone_number in range(1, 101):\n",
    "    for client_number in range(1, 11):\n",
    "        sample_name = str(zone_number)+'_sample_'+str(client_number)+'.csv'\n",
    "\n",
    "        with open(sample_name, newline='') as sample_csv:\n",
    "    \n",
    "            sample = list(csv.reader(sample_csv))[1:]\n",
    "\n",
    "            set_source.update([q[2] for q in sample])\n",
    "            set_dest.update([q[3] for q in sample])\n",
    "            set_pairs.update([(q[2], q[3])for q in sample])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(set_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that there are a very little set of used ip addresses, so we tried to find which could be more important/interesting than other. We saw that the most important (as well as used) are communication between \n",
    "\n",
    "- '10.0.2.15' and '54.93.77.70'\n",
    "- '10.0.2.15' and '62.210.85.178'\n",
    "\n",
    "What is interesting to notice is that there is no communication at all between '62.210.85.178' and '54.93.77.70'. Also, there is generally more messages between '10.0.2.15' and '62.210.85.178': we could use it to find if it is because of the impact of the zone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ip_10_54(sample_data):\n",
    "    #return all communication between '10.0.2.15' and '54.93.77.70' \n",
    "    return [q[1:] for q in sample_data if((q[2]=='10.0.2.15' and q[3]=='54.93.77.70') or \n",
    "            (q[2]=='54.93.77.70' and q[3]=='10.0.2.15'))]\n",
    "\n",
    "def ip_10_62(sample_data):\n",
    "    #return all communication between '10.0.2.15' and '62.210.85.178'\n",
    "    return [q[1:] for q in sample_data if((q[2]=='10.0.2.15' and q[3]=='62.210.85.178') or \n",
    "                                      (q[2]=='62.210.85.178' and q[3]=='10.0.2.15'))] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we found out is that there is two type of messages in a communication: TCP messages and TLS messages. So we now want to try to separate them and see if we can do something about them. TLS messages have always \"application data\" information, which mean that those are messages from the application, that carries user request and server's answer. We found out that there is more TCP messages than TLS messages, so we will try to use this information as a feature as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tls(sample_data):\n",
    "    #return only tcp messages. Sample data should be data returned by ip_10_54 or ip_10_62 functions\n",
    "    return [q for q in sample_data if(q[3]!='TLSv1.2')]\n",
    "\n",
    "def remove_tcp(sample_data):\n",
    "    #return only tls messages. Sample data should be data returned by ip_10_54 or ip_10_62 functions\n",
    "    return [q for q in sample_data if(q[3]!='TCP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another column we need to clean and extract some features: the information columns when it's a TCP message. First thing we do with them is to delete all samples concerning TCP retransmission and duplicate ack: we are sure they don't concern our problematic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tcp_ret(sample_data):\n",
    "    #Return TCP messages without TCP retransmission and without duplicate ACK messages.\n",
    "    #Sample data should be the output of remove_tls function\n",
    "    #the output will be a list of following features [time, src, dest, prot, len, info]\n",
    "    \n",
    "    return [q for q in sample_data if(q[5].split()[0]!='[TCP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_to_list(info):\n",
    "    #Take the info string as input: it has only 3 patterns of them\n",
    "    #1st pattern : '35978  >  9001 [ACK] Seq=99468683 Ack=5554741 Win=65535 Len=0'\n",
    "    #2nd pattern : '35978  >  9001 [ACK] Seq=99479995 Ack=5555813 Win=65535 Len=2920 [TCP segment of a reassembled PDU]'\n",
    "    #3rd pattern : '9001  >  34692 [PSH, ACK] Seq=1073 Ack=2101 Win=65535 Len=1448 [TCP segment of a reassembled PDU]'\n",
    "    # return list : [start, end, seq_number, ack_number, win_len, len]\n",
    "    #if this is a reassembled PDU segment, len!=0, otherwise len=0\n",
    "    \n",
    "    l = info.split()\n",
    "    \n",
    "    \n",
    "    start = int(l[0])\n",
    "    end = int(l[2])\n",
    "    \n",
    "    if(l[3][1:2]=='P'):\n",
    "        seq_number= int(l[5][4:])\n",
    "        ack_number, win_len, len_seg = int(l[6][4:]), int(l[6][4:]), int(l[8][4:])\n",
    "    else:\n",
    "        seq_number= int(l[4][4:])\n",
    "        ack_number, win_len, len_seg = int(l[5][4:]), int(l[6][4:]), int(l[7][4:])\n",
    "    \n",
    "    return [start, end, seq_number, ack_number, win_len, len_seg]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the features we can extract from the TCP information column are:\n",
    "\n",
    "- average of the window size\n",
    "- what is the freqency of reassembled PDU messages\n",
    "\n",
    "We though that seq_number isn't pertinent for our analyze of the data, as well as the start and the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_window_size(sample_data):\n",
    "    #the input is a list of [time, src_ip, dst_ip, length, start, end, seq_number, ack_number, win_len, len_seg]\n",
    "    #every line is a TCP communication\n",
    "    #return the average size of the window\n",
    "    return sum([q[8] for q in sample_data])/len(sample_data)\n",
    "    \n",
    "def avg_pdu_ass(sample_data):\n",
    "    #the input is a list of [time, src_ip, dst_ip, length, start, end, seq_number, ack_number, win_len, len_seg]\n",
    "    #every line is a TCP communication\n",
    "    #The function computes the average frequency of reassembled PDU messages: \n",
    "    #if the reassamble PDU message is the fourth one (-, -, -, reassembled_packet) => the function will return 1/3\n",
    "    \n",
    "    p = [[1, 0] if(q[9]==0) else [0, 1] for q in sample_data]\n",
    "    \n",
    "    res = [sum(x) for x in zip(*p)]\n",
    "    return res[1]/res[0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating data and the model\n",
    "Now we will assemble all function defined in previous part and train our model on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data creation\n",
    "data = []\n",
    "\n",
    "for zone_number in range(1, 101):\n",
    "    for client_number in range(1, 11):\n",
    "        sample_name = str(zone_number)+'_sample_'+str(client_number)+'.csv'\n",
    "\n",
    "        with open(sample_name, newline='') as sample_csv:\n",
    "    \n",
    "            sample = list(csv.reader(sample_csv))[1:]\n",
    "        \n",
    "            '''\n",
    "            Our features would be:\n",
    "            - total time, total_len\n",
    "            - fraction 10_62packets/tot_len\n",
    "            - fraction 10_54packets/tot_len\n",
    "            - avg window size for 10_62\n",
    "            - avg pdu_assemblage for 10_62\n",
    "            - avg window size for 10_54\n",
    "            - avg pdu_assemblage for 10_54\n",
    "            \n",
    "            - total tls packets 10_62\n",
    "            - total tcp packets 10_62\n",
    "            - total tls packets 10_54\n",
    "            - total tcp packets 10_54\n",
    "            \n",
    "            - frac tls packets 10_62/ tot packets 10_62\n",
    "            - frac tls packets 10_54/ tot packets 10_54\n",
    "            \n",
    "            '''\n",
    "            tot_len = total_len(sample)\n",
    "            \n",
    "            list_10_62 = ip_10_62(sample)\n",
    "            list_10_54 = ip_10_54(sample)\n",
    "            \n",
    "            frac_10_62 = len(list_10_62)/tot_len\n",
    "            frac_10_54 = len(list_10_54)/tot_len\n",
    "            \n",
    "            tcp_10_62 = remove_tcp_ret(remove_tls(list_10_62))\n",
    "            tcp_10_54 = remove_tcp_ret(remove_tls(list_10_54))\n",
    "\n",
    "            \n",
    "            #process the last string\n",
    "            tcp_10_62 = [q[:3]+[q[4]]+info_to_list(q[5]) for q in tcp_10_62]\n",
    "            tcp_10_54 = [q[:3]+[q[4]]+info_to_list(q[5]) for q in tcp_10_54]\n",
    "            \n",
    "            avg_wdw_10_62 = avg_window_size(tcp_10_62)\n",
    "            avg_pdu_10_62 = avg_pdu_ass(tcp_10_62)\n",
    "            \n",
    "            avg_wdw_10_54 = avg_window_size(tcp_10_54)\n",
    "            avg_pdu_10_54 = avg_pdu_ass(tcp_10_54)\n",
    "            \n",
    "            #tot tls/tcp packets\n",
    "            tot_tcp_10_62_len = len(tcp_10_62)\n",
    "            tot_tcp_10_54_len = len(tcp_10_54)\n",
    "            \n",
    "            tls_10_62 = remove_tcp(list_10_62)\n",
    "            tls_10_54 = remove_tcp(list_10_54)\n",
    "            \n",
    "            tot_tls_10_62_len = len(tls_10_62)\n",
    "            tot_tls_10_54_len = len(tls_10_54)\n",
    "            \n",
    "            #frac tls packets / tot packets \n",
    "            frac_tls_10_62 = tot_tls_10_62_len/len(list_10_62)\n",
    "            frac_tls_10_54 = tot_tls_10_54_len/len(list_10_54)\n",
    "            \n",
    "            \n",
    "            cleaned = [total_time(sample), tot_len, frac_10_62, frac_10_54, \n",
    "                       avg_wdw_10_62, avg_pdu_10_62, avg_wdw_10_54, avg_pdu_10_54,\n",
    "                       tot_tcp_10_62_len, tot_tcp_10_54_len, tot_tls_10_62_len, tot_tls_10_54_len, \n",
    "                       frac_tls_10_62, frac_tls_10_54, zone_number-1]\n",
    "            \n",
    "            data.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we shuffle the data and create X and Y arrays: X is the data and Y is what is the correct answer of the zone\n",
    "shuffle(data)\n",
    "\n",
    "X, Y = np.array([q[:14] for q in data]), np.array([q[14:][0] for q in data])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode creation\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(14,))\n",
    "    i1 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(inputs)\n",
    "    i2 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i1)\n",
    "    i3 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i2)\n",
    "    i4 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i3)\n",
    "    i5 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i4)\n",
    "    i6 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i5)\n",
    "    i7 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i6)\n",
    "    i8 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i7)\n",
    "    i9 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i8)\n",
    "    i10 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i9)\n",
    "    i11 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i10)\n",
    "    i12 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i11)\n",
    "    i13 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i12)\n",
    "    i14 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i13)\n",
    "    i15 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i14)\n",
    "    i16 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i15)\n",
    "    i17 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i16)\n",
    "    i18 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i17)\n",
    "    i19 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i18)\n",
    "    i20 = tf.keras.layers.Dense(14, activation=tf.nn.relu)(i19)\n",
    "\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(1)(i20)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    " \n",
    "    model.compile(loss = \"mean_squared_error\" , optimizer = 'adam' , metrics = ['accuracy'] )\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pred, truth):\n",
    "    #pred is predictions returned by the model, numbers are not rounded\n",
    "    #truth is all correct zones\n",
    "    #this function return the accuracy of the predictions\n",
    "    pred_rounded = [round(z[0]) for z in list(pred)]\n",
    "    \n",
    "    zipped = zip(list(truth), pred_rounded)\n",
    "    correct_guessed = [1 if(z[0]==z[1]) else 0 for z in zipped]\n",
    "    \n",
    "    return sum(correct_guessed)/100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#we compute here the accuracy for a n_split=10 k-fold cross validation model\n",
    "n_split=10\n",
    "\n",
    "evals= list()\n",
    "acc = list()\n",
    " \n",
    "for train_index,test_index in KFold(n_split).split(X):\n",
    "    x_train,x_test=X[train_index],X[test_index]\n",
    "    y_train,y_test=Y[train_index],Y[test_index]\n",
    "  \n",
    "    model=create_model()\n",
    "    model.fit(x_train, y_train, epochs=2000)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    a = compute_accuracy(pred, y_test)\n",
    "    \n",
    "    print(\"Accuracy: \", a)\n",
    "    acc.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in acc:\n",
    "    print(i)\n",
    "\n",
    "accuracy_avg = sum(acc)/10\n",
    "print(\"Our final accuracy is: \", accuracy_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
